{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42 #Number of life :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacer resize y guardar una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_img(src, destination_path):\n",
    "    original_img = cv2.imread(src)\n",
    "    old_image_height, old_image_width, channels = original_img.shape\n",
    "    new_image_width = 60        \n",
    "    new_image_height = 60\n",
    "    color = (255,255,255)\n",
    "\n",
    "    result = np.full((new_image_height, new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # Centrar imagen\n",
    "    result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = original_img\n",
    "\n",
    "    Image.fromarray(result).save(destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificar data de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_data():\n",
    "    train_dir = \"Data/Train/\"\n",
    "    test_dir = \"Data/Test/\"\n",
    "    destination_dir = \"Data_preprocesada/\"\n",
    "\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        for train_img in os.listdir(train_dir+class_dir):\n",
    "            resize_and_save_img(f\"{train_dir}{class_dir}/{train_img}\", f\"{destination_dir}{class_dir}/{train_img}\")\n",
    "\n",
    "    test_info = pd.read_csv(\"Data/Test.csv\")\n",
    "    for i, test_img in enumerate(sorted(os.listdir(test_dir))):\n",
    "        resize_and_save_img(f\"{test_dir}{test_img}\", f\"{destination_dir}{test_info.ClassId[i]}/{test_img}\")\n",
    "\n",
    "#generate_new_data() Se corre solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_from_image(image, iterations):\n",
    "    LL, (LH, HL, HH) = pywt.dwt2(image, 'haar')\n",
    "    for _ in range(iterations - 1):\n",
    "        LL, (LH, HL, HH) = pywt.dwt2(LL, 'haar')\n",
    "    return LL.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener data (estratificada y no estratificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(src_dir, iterations):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for class_dir in os.listdir(src_dir):\n",
    "        for train_img in os.listdir(src_dir + class_dir):\n",
    "            image_path = f\"{src_dir}{class_dir}/{train_img}\"\n",
    "            img = Image.open(image_path)\n",
    "            fv = get_vector_from_image(img, iterations)\n",
    "            x.append(fv)\n",
    "            y.append(int(class_dir))\n",
    "    return np.asarray(x), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    columns = data.transpose()\n",
    "    normalized_data = []\n",
    "    for column in columns:\n",
    "        minimum = min(column)\n",
    "        maximum = max(column)\n",
    "        normalized_column = np.asarray([(n - minimum) / (maximum - minimum) for n in column])\n",
    "        normalized_data.append(normalized_column)\n",
    "    return np.asarray(normalized_data).transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stratified_k_fold_cross_validation(X, y, number_of_folds, random_seed):\n",
    "    skf = StratifiedKFold(n_splits=number_of_folds, shuffle=True, random_state=random_seed)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "    k_folds = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        fold = {}\n",
    "        fold['X_train'] = X[train_index]\n",
    "        fold['X_test'] = X[test_index]\n",
    "        fold['y_train'] = y[train_index]\n",
    "        fold['y_test'] = y[test_index]\n",
    "        k_folds.append(fold)\n",
    "    \n",
    "    return k_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation no Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_stratified_k_fold_cross_validation(X, y, number_of_folds, random_seed):\n",
    "    kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=random_seed)\n",
    "    kf.get_n_splits(X)\n",
    "    k_folds = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold = {}\n",
    "        fold['X_train'] = X[train_index]\n",
    "        fold['X_test'] = X[test_index]\n",
    "        fold['y_train'] = y[train_index]\n",
    "        fold['y_test'] = y[test_index]\n",
    "        k_folds.append(fold)\n",
    "    return k_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60ba1e9c20a97bab95adc8fa7cd7536eabf7ae0f08621d987aa706dba1e5c7d3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
