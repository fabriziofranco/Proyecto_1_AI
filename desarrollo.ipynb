{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacer resize y guardar una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_img(src, destination_path):\n",
    "    original_img = cv2.imread(src)\n",
    "    old_image_height, old_image_width, channels = original_img.shape\n",
    "    new_image_width = 60        \n",
    "    new_image_height = 60\n",
    "    color = (255,255,255)\n",
    "\n",
    "    result = np.full((new_image_height, new_image_width, channels), color, dtype=np.uint8)\n",
    "\n",
    "    x_center = (new_image_width - old_image_width) // 2\n",
    "    y_center = (new_image_height - old_image_height) // 2\n",
    "\n",
    "    # Centrar imagen\n",
    "    result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = original_img\n",
    "\n",
    "    Image.fromarray(result).save(destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificar data de Train y Test\n",
    "\n",
    "Se realizará split propio posteriormente (70% TRAIN y 30% TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_data():\n",
    "    train_dir = \"Data/Train/\"\n",
    "    test_dir = \"Data/Test/\"\n",
    "    destination_dir = \"Data_preprocesada/\"\n",
    "\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        for train_img in os.listdir(train_dir+class_dir):\n",
    "            resize_and_save_img(f\"{train_dir}{class_dir}/{train_img}\", f\"{destination_dir}{class_dir}/{train_img}\")\n",
    "\n",
    "    test_info = pd.read_csv(\"Data/Test.csv\")\n",
    "    for i, test_img in enumerate(sorted(os.listdir(test_dir))):\n",
    "        resize_and_save_img(f\"{test_dir}{test_img}\", f\"{destination_dir}{test_info.ClassId[i]}/{test_img}\")\n",
    "\n",
    "generate_new_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_from_image(image, iterations):\n",
    "    LL, (LH, HL, HH) = pywt.dwt2(image, 'haar')\n",
    "    for _ in range(iterations - 1):\n",
    "        LL, (LH, HL, HH) = pywt.dwt2(LL, 'haar')\n",
    "    return LL.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener data (estratificada y no estratificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(src_dir, iterations, number_of_classes):\n",
    "    x_by_class = [[] for _ in range(number_of_classes)]\n",
    "    x = []\n",
    "    for class_dir in os.listdir(src_dir):\n",
    "        for train_img in os.listdir(src_dir + class_dir):\n",
    "            image_path = f\"{src_dir}{class_dir}/{train_img}\"\n",
    "            img = Image.open(image_path)\n",
    "            fv = get_vector_from_image(img, iterations)\n",
    "            x_by_class[int(class_dir)].append(fv)\n",
    "            x.append(fv)\n",
    "    return np.asarray(x_by_class), np.asarray(x)[np.random.permutation(len(x))] # stratified, non stratified\n",
    "\n",
    "stratified_data, non_stratified_data = get_data(src_dir=\"Data_preprocesada/\", iterations=5, number_of_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de muestras por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 195,\n",
       " 1: 2158,\n",
       " 2: 2466,\n",
       " 3: 1599,\n",
       " 4: 2239,\n",
       " 5: 2210,\n",
       " 6: 522,\n",
       " 7: 1640,\n",
       " 8: 1648,\n",
       " 9: 1560}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = { }\n",
    "for i in range(len(stratified_data)):\n",
    "    counts[i] = len(stratified_data[i])\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de caracteristicas por muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(stratified_data[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stratified_k_fold_cross_validation(stratified_data, number_of_folds):\n",
    "    categories = len(stratified_data)\n",
    "\n",
    "    data_by_fold = [] #Cada Fold tendrá un diccionario de X_train,X_test,y_train, y_test\n",
    "    \n",
    "    for fold in range(number_of_folds):\n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        y_train = []\n",
    "        y_test = []\n",
    "\n",
    "        for category in categories:\n",
    "            offset_size = math.round(stratified_data[category]/number_of_folds)\n",
    "            upper_bound = fold\n",
    "            lower_bound = fold\n",
    "            \n",
    "            if upper_bound>len(stratified_data[category]):\n",
    "                upper_bound = len(stratified_data[category])\n",
    "\n",
    "            #0 1 2 3 4 5 6 7 8 9\n",
    "            #0 1 2 3 4 5 6 7 8 9\n",
    "\n",
    "11\n",
    "\n",
    "\n",
    "10/4 = 3\n",
    "\n",
    "3 3   1\n",
    "\n",
    "11/4 = 3\n",
    "\n",
    "3 3 3 2\n",
    "10/4 = 3 3 3 1\n",
    "9/4 = 2 2 2 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "print(\"hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_stratified_split_train_test_classes(X_vectors, labels):\n",
    "    categories = np.unique(labels).tolist()\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        labels_i = [i for _ in range(len(X_vectors[i]))]\n",
    "        Xi_train, Xi_test, yi_train, yi_test = train_test_split(X_vectors[i], labels_i, test_size=0.3)\n",
    "\n",
    "        X_train += Xi_train\n",
    "        X_test += Xi_test\n",
    "        y_train += yi_train\n",
    "        y_test += yi_test\n",
    "\n",
    "    return np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "\n",
    "ns_X_train, ns_X_test, ns_y_train, ns_y_test = non_stratified_split_train_test_classes(X_vectors, labels)\n",
    "ns_X_train, ns_y_train = unison_shuffled_copies(X_train, y_train)\n",
    "ns_X_test, ns_y_test = unison_shuffled_copies(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation no Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_stratified_k_fold_cross_validation(X, y, number_of_folds):\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60ba1e9c20a97bab95adc8fa7cd7536eabf7ae0f08621d987aa706dba1e5c7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
