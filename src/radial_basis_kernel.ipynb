{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilitarios as utils #Funciones propias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42 #Number of life :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de muestras por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations=1)\n",
    "\n",
    "categories, counts =  np.unique(y, return_counts=True)\n",
    "dict(zip(categories, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_k_fold(min_cuts , max_cuts, max_folds, k_fold_func):\n",
    "    X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations= min_cuts-1)\n",
    "\n",
    "    dataframe = []\n",
    "    columns = ['Number of cuts', 'Length of X', 'K fold',\n",
    "                'Train error', 'Train var. error', 'Train bias error', 'Train list errors',\n",
    "                'Test error', 'Test var. error', 'Test bias error', 'Test list errors',\n",
    "                ]\n",
    "\n",
    "    for iteration in range(min_cuts, max_cuts+1):\n",
    "        X, X_raw = utils.iterate_data(X_raw)\n",
    "        X = utils.normalization(X)\n",
    "        X_length = len(X[0])\n",
    "\n",
    "\n",
    "        for number_of_folds in range(2, max_folds+1):\n",
    "            data_aux = [iteration, X_length, number_of_folds]\n",
    "\n",
    "            k_folds_data = k_fold_func(X, y, number_of_folds, random_seed)\n",
    "\n",
    "            clf = make_pipeline(StandardScaler(), \n",
    "                                NuSVC(nu=0.10,kernel='rbf', class_weight = 'balanced',\n",
    "                                            random_state=random_seed, decision_function_shape='ovr', break_ties=True))\n",
    "\n",
    "            error_train = 0\n",
    "            bias_train = 0\n",
    "            varianza_train = 0\n",
    "            list_of_errors_train = []\n",
    "\n",
    "            error_test = 0\n",
    "            bias_test = 0\n",
    "            varianza_test = 0\n",
    "            list_of_errors_test = []\n",
    "\n",
    "            for i in range(number_of_folds):\n",
    "                clf.fit(k_folds_data[i]['X_train'], k_folds_data[i]['y_train'])\n",
    "\n",
    "                error_i_train = 1 - clf.score(k_folds_data[i]['X_train'], k_folds_data[i]['y_train'])\n",
    "                error_i_test = 1 - clf.score(k_folds_data[i]['X_test'], k_folds_data[i]['y_test'])\n",
    "\n",
    "                error_i_train = round(error_i_train,6)\n",
    "                error_i_test = round(error_i_test,6)\n",
    "\n",
    "                list_of_errors_train.append(error_i_train)\n",
    "                list_of_errors_test.append(error_i_test)\n",
    "\n",
    "            error_train = sum(list_of_errors_train) / len(list_of_errors_train)\n",
    "            error_test = sum(list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "\n",
    "            varianza_train = sum((x-error_train)**2 for x in list_of_errors_train) / len(list_of_errors_train)\n",
    "            varianza_test = sum((x-error_test)**2 for x in list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "            bias_train = math.sqrt(error_train - varianza_train)\n",
    "            bias_test = math.sqrt(error_test - varianza_test)\n",
    "\n",
    "\n",
    "            data_aux.extend([error_train,varianza_train, bias_train,list_of_errors_train])\n",
    "            data_aux.extend([error_test,varianza_test, bias_test,list_of_errors_test])\n",
    "\n",
    "            dataframe.append(data_aux)\n",
    "\n",
    "    dataframe = pd.DataFrame(data = dataframe, columns = columns)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bootstrap(min_cuts, max_cuts, max_subsets, training_sample):\n",
    "\n",
    "    X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations= min_cuts-1)\n",
    "\n",
    "    dataframe = []\n",
    "    columns = ['Number of cuts', 'Length of X', 'K subsets',\n",
    "                'Train error', 'Train var. error', 'Train bias error', 'Train list errors',\n",
    "                'Test error', 'Test var. error', 'Test bias error', 'Test list errors',\n",
    "                ]\n",
    "\n",
    "\n",
    "    for iteration in range(min_cuts, max_cuts+1):\n",
    "        X, X_raw = utils.iterate_data(X_raw)\n",
    "        X = utils.normalization(X)\n",
    "        X_length = len(X[0])\n",
    "\n",
    "\n",
    "        for number_of_subsets in range(1, max_subsets+1):\n",
    "            data_aux = [iteration, X_length, number_of_subsets]\n",
    "\n",
    "            k_subsets_data = utils.get_bootstrap_subsets(X, y, number_of_subsets, training_sample, random_seed)\n",
    "\n",
    "            clf = make_pipeline(StandardScaler(), \n",
    "                                NuSVC(nu=0.10,kernel='rbf', class_weight = 'balanced',\n",
    "                                            random_state=random_seed, decision_function_shape='ovr', break_ties=True))\n",
    "\n",
    "            error_train = 0\n",
    "            bias_train = 0\n",
    "            varianza_train = 0\n",
    "            list_of_errors_train = []\n",
    "\n",
    "            error_test = 0\n",
    "            bias_test = 0\n",
    "            varianza_test = 0\n",
    "            list_of_errors_test = []\n",
    "\n",
    "            for i in range(number_of_subsets):\n",
    "                clf.fit(k_subsets_data[i]['X_train'], k_subsets_data[i]['y_train'])\n",
    "\n",
    "                error_i_train = 1 - clf.score(k_subsets_data[i]['X_train'], k_subsets_data[i]['y_train'])\n",
    "                error_i_test = 1 - clf.score(k_subsets_data[i]['X_test'], k_subsets_data[i]['y_test'])\n",
    "\n",
    "                error_i_train = round(error_i_train,6)\n",
    "                error_i_test = round(error_i_test,6)\n",
    "\n",
    "                list_of_errors_train.append(error_i_train)\n",
    "                list_of_errors_test.append(error_i_test)\n",
    "\n",
    "            error_train = sum(list_of_errors_train) / len(list_of_errors_train)\n",
    "            error_test = sum(list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "\n",
    "            varianza_train = sum((x-error_train)**2 for x in list_of_errors_train) / len(list_of_errors_train)\n",
    "            varianza_test = sum((x-error_test)**2 for x in list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "            bias_train = math.sqrt(error_train - varianza_train)\n",
    "            bias_test = math.sqrt(error_test - varianza_test)\n",
    "\n",
    "\n",
    "            data_aux.extend([error_train,varianza_train, bias_train,list_of_errors_train])\n",
    "            data_aux.extend([error_test,varianza_test, bias_test,list_of_errors_test])\n",
    "\n",
    "            dataframe.append(data_aux)\n",
    "\n",
    "    dataframe_bootstrap = pd.DataFrame(data = dataframe, columns = columns)\n",
    "    return dataframe_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimientaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cuts = 3\n",
    "max_cuts =  8\n",
    "max_folds = 8\n",
    "\n",
    "resultados_test_stratified_k_fold = test_k_fold(min_cuts,max_cuts,max_folds,k_fold_func=utils.get_stratified_k_fold_cross_validation)\n",
    "resultados_test_stratified_k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cuts = 3\n",
    "max_cuts =  8\n",
    "max_folds = 8\n",
    "\n",
    "resultados_test_non_stratified_k_fold = test_k_fold(min_cuts,max_cuts,max_folds,k_fold_func=utils.get_non_stratified_k_fold_cross_validation)\n",
    "resultados_test_non_stratified_k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cuts = 3\n",
    "max_cuts =  8\n",
    "max_subsets = 6 \n",
    "training_sample = 0.70\n",
    "\n",
    "resultados_test_bootstrap = test_bootstrap(min_cuts, max_cuts, max_subsets, training_sample)\n",
    "resultados_test_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Resultados/radial_basis_kernel/'\n",
    "resultados_test_stratified_k_fold.to_csv(output_path + 'stratified_k_fold.csv', sep = \";\")\n",
    "resultados_test_non_stratified_k_fold.to_csv(output_path + 'non_stratified_k_fold.csv', sep = \";\")\n",
    "resultados_test_bootstrap.to_csv(output_path + 'bootstrap.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilitarios as utils #Funciones propias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42 #Number of life :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 195,\n",
       " 1: 2158,\n",
       " 2: 2466,\n",
       " 3: 1599,\n",
       " 4: 2239,\n",
       " 5: 2210,\n",
       " 6: 522,\n",
       " 7: 1640,\n",
       " 8: 1648,\n",
       " 9: 1560}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations=1)\n",
    "\n",
    "categories, counts =  np.unique(y, return_counts=True)\n",
    "dict(zip(categories, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_k_fold(min_cuts , max_cuts, max_folds, k_fold_func):\n",
    "    X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations= min_cuts-1)\n",
    "\n",
    "    dataframe = []\n",
    "    columns = ['Number of cuts', 'Length of X', 'K fold',\n",
    "                'Train error', 'Train var. error', 'Train bias error', 'Train list errors',\n",
    "                'Test error', 'Test var. error', 'Test bias error', 'Test list errors',\n",
    "                ]\n",
    "\n",
    "    for iteration in range(min_cuts, max_cuts+1):\n",
    "        X, X_raw = utils.iterate_data(X_raw)\n",
    "        X = utils.normalization(X)\n",
    "        X_length = len(X[0])\n",
    "\n",
    "\n",
    "        for number_of_folds in range(2, max_folds+1):\n",
    "            data_aux = [iteration, X_length, number_of_folds]\n",
    "\n",
    "            k_folds_data = k_fold_func(X, y, number_of_folds, random_seed)\n",
    "\n",
    "            clf = make_pipeline(StandardScaler(), \n",
    "                                NuSVC(nu=0.10,kernel='rbf', class_weight = 'balanced',\n",
    "                                            random_state=random_seed, decision_function_shape='ovr', break_ties=True))\n",
    "\n",
    "            error_train = 0\n",
    "            bias_train = 0\n",
    "            varianza_train = 0\n",
    "            list_of_errors_train = []\n",
    "\n",
    "            error_test = 0\n",
    "            bias_test = 0\n",
    "            varianza_test = 0\n",
    "            list_of_errors_test = []\n",
    "\n",
    "            for i in range(number_of_folds):\n",
    "                clf.fit(k_folds_data[i]['X_train'], k_folds_data[i]['y_train'])\n",
    "\n",
    "                error_i_train = 1 - clf.score(k_folds_data[i]['X_train'], k_folds_data[i]['y_train'])\n",
    "                error_i_test = 1 - clf.score(k_folds_data[i]['X_test'], k_folds_data[i]['y_test'])\n",
    "\n",
    "                error_i_train = round(error_i_train,6)\n",
    "                error_i_test = round(error_i_test,6)\n",
    "\n",
    "                list_of_errors_train.append(error_i_train)\n",
    "                list_of_errors_test.append(error_i_test)\n",
    "\n",
    "            error_train = sum(list_of_errors_train) / len(list_of_errors_train)\n",
    "            error_test = sum(list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "\n",
    "            varianza_train = sum((x-error_train)**2 for x in list_of_errors_train) / len(list_of_errors_train)\n",
    "            varianza_test = sum((x-error_test)**2 for x in list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "            bias_train = math.sqrt(error_train - varianza_train)\n",
    "            bias_test = math.sqrt(error_test - varianza_test)\n",
    "\n",
    "\n",
    "            data_aux.extend([error_train,varianza_train, bias_train,list_of_errors_train])\n",
    "            data_aux.extend([error_test,varianza_test, bias_test,list_of_errors_test])\n",
    "\n",
    "            dataframe.append(data_aux)\n",
    "\n",
    "    dataframe = pd.DataFrame(data = dataframe, columns = columns)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bootstrap(min_cuts, max_cuts, max_subsets, training_sample):\n",
    "\n",
    "    X, y, X_raw = utils.get_data(src_dir=\"Data_preprocesada/\", iterations= min_cuts-1)\n",
    "\n",
    "    dataframe = []\n",
    "    columns = ['Number of cuts', 'Length of X', 'K subsets',\n",
    "                'Train error', 'Train var. error', 'Train bias error', 'Train list errors',\n",
    "                'Test error', 'Test var. error', 'Test bias error', 'Test list errors',\n",
    "                ]\n",
    "\n",
    "\n",
    "    for iteration in range(min_cuts, max_cuts+1):\n",
    "        X, X_raw = utils.iterate_data(X_raw)\n",
    "        X = utils.normalization(X)\n",
    "        X_length = len(X[0])\n",
    "\n",
    "\n",
    "        for number_of_subsets in range(1, max_subsets+1):\n",
    "            data_aux = [iteration, X_length, number_of_subsets]\n",
    "\n",
    "            k_subsets_data = utils.get_bootstrap_subsets(X, y, number_of_subsets, training_sample, random_seed)\n",
    "\n",
    "            clf = make_pipeline(StandardScaler(), \n",
    "                                NuSVC(nu=0.10,kernel='rbf', class_weight = 'balanced',\n",
    "                                            random_state=random_seed, decision_function_shape='ovr', break_ties=True))\n",
    "\n",
    "            error_train = 0\n",
    "            bias_train = 0\n",
    "            varianza_train = 0\n",
    "            list_of_errors_train = []\n",
    "\n",
    "            error_test = 0\n",
    "            bias_test = 0\n",
    "            varianza_test = 0\n",
    "            list_of_errors_test = []\n",
    "\n",
    "            for i in range(number_of_subsets):\n",
    "                clf.fit(k_subsets_data[i]['X_train'], k_subsets_data[i]['y_train'])\n",
    "\n",
    "                error_i_train = 1 - clf.score(k_subsets_data[i]['X_train'], k_subsets_data[i]['y_train'])\n",
    "                error_i_test = 1 - clf.score(k_subsets_data[i]['X_test'], k_subsets_data[i]['y_test'])\n",
    "\n",
    "                error_i_train = round(error_i_train,6)\n",
    "                error_i_test = round(error_i_test,6)\n",
    "\n",
    "                list_of_errors_train.append(error_i_train)\n",
    "                list_of_errors_test.append(error_i_test)\n",
    "\n",
    "            error_train = sum(list_of_errors_train) / len(list_of_errors_train)\n",
    "            error_test = sum(list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "\n",
    "            varianza_train = sum((x-error_train)**2 for x in list_of_errors_train) / len(list_of_errors_train)\n",
    "            varianza_test = sum((x-error_test)**2 for x in list_of_errors_test) / len(list_of_errors_test)\n",
    "\n",
    "            bias_train = math.sqrt(error_train - varianza_train)\n",
    "            bias_test = math.sqrt(error_test - varianza_test)\n",
    "\n",
    "\n",
    "            data_aux.extend([error_train,varianza_train, bias_train,list_of_errors_train])\n",
    "            data_aux.extend([error_test,varianza_test, bias_test,list_of_errors_test])\n",
    "\n",
    "            dataframe.append(data_aux)\n",
    "\n",
    "    dataframe_bootstrap = pd.DataFrame(data = dataframe, columns = columns)\n",
    "    return dataframe_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of cuts</th>\n",
       "      <th>Length of X</th>\n",
       "      <th>K fold</th>\n",
       "      <th>Train error</th>\n",
       "      <th>Train var. error</th>\n",
       "      <th>Train bias error</th>\n",
       "      <th>Train list errors</th>\n",
       "      <th>Test error</th>\n",
       "      <th>Test var. error</th>\n",
       "      <th>Test bias error</th>\n",
       "      <th>Test list errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>7.404603e-07</td>\n",
       "      <td>0.165734</td>\n",
       "      <td>[0.026608, 0.028329]</td>\n",
       "      <td>0.212108</td>\n",
       "      <td>2.414740e-05</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>[0.217022, 0.207194]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>3</td>\n",
       "      <td>0.028454</td>\n",
       "      <td>4.770576e-07</td>\n",
       "      <td>0.168681</td>\n",
       "      <td>[0.028271, 0.029376, 0.027714]</td>\n",
       "      <td>0.176756</td>\n",
       "      <td>5.066776e-05</td>\n",
       "      <td>0.420364</td>\n",
       "      <td>[0.183263, 0.180155, 0.166851]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029562</td>\n",
       "      <td>1.845412e-07</td>\n",
       "      <td>0.171936</td>\n",
       "      <td>[0.028825, 0.02989, 0.029808, 0.029726]</td>\n",
       "      <td>0.169243</td>\n",
       "      <td>2.616685e-05</td>\n",
       "      <td>0.411359</td>\n",
       "      <td>[0.175862, 0.171717, 0.167283, 0.162109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>8.330122e-07</td>\n",
       "      <td>0.172559</td>\n",
       "      <td>[0.02864, 0.031026, 0.028945, 0.030562, 0.029715]</td>\n",
       "      <td>0.161606</td>\n",
       "      <td>2.625967e-05</td>\n",
       "      <td>0.401969</td>\n",
       "      <td>[0.170567, 0.164101, 0.157376, 0.157376, 0.158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>6</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>5.156348e-07</td>\n",
       "      <td>0.172507</td>\n",
       "      <td>[0.028899, 0.029931, 0.030596, 0.030301, 0.028...</td>\n",
       "      <td>0.158342</td>\n",
       "      <td>6.389788e-05</td>\n",
       "      <td>0.397841</td>\n",
       "      <td>[0.165127, 0.153363, 0.17221, 0.150776, 0.1504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>7</td>\n",
       "      <td>0.030239</td>\n",
       "      <td>8.991320e-07</td>\n",
       "      <td>0.173892</td>\n",
       "      <td>[0.030754, 0.030466, 0.030969, 0.029173, 0.030...</td>\n",
       "      <td>0.157171</td>\n",
       "      <td>8.939856e-06</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>[0.159483, 0.159052, 0.160345, 0.159483, 0.152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>8</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>4.266609e-07</td>\n",
       "      <td>0.174045</td>\n",
       "      <td>[0.031604, 0.029633, 0.030196, 0.030689, 0.030...</td>\n",
       "      <td>0.152614</td>\n",
       "      <td>3.001696e-05</td>\n",
       "      <td>0.390620</td>\n",
       "      <td>[0.149261, 0.159606, 0.157635, 0.156158, 0.150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>1.224342e-06</td>\n",
       "      <td>0.186701</td>\n",
       "      <td>[0.033752, 0.035965]</td>\n",
       "      <td>0.274189</td>\n",
       "      <td>9.379922e-07</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>[0.275157, 0.27322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>6.881742e-07</td>\n",
       "      <td>0.196976</td>\n",
       "      <td>[0.038803, 0.039815, 0.037783]</td>\n",
       "      <td>0.239699</td>\n",
       "      <td>7.302089e-06</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>[0.243118, 0.239468, 0.236511]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>1.249681e-06</td>\n",
       "      <td>0.199615</td>\n",
       "      <td>[0.038269, 0.040729, 0.041058, 0.039333]</td>\n",
       "      <td>0.228983</td>\n",
       "      <td>9.266302e-07</td>\n",
       "      <td>0.478521</td>\n",
       "      <td>[0.227833, 0.228381, 0.230352, 0.229367]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>6.294814e-07</td>\n",
       "      <td>0.202716</td>\n",
       "      <td>[0.040727, 0.040111, 0.041493, 0.042417, 0.040...</td>\n",
       "      <td>0.220606</td>\n",
       "      <td>4.904469e-05</td>\n",
       "      <td>0.469635</td>\n",
       "      <td>[0.220135, 0.231527, 0.220511, 0.209424, 0.221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>6</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>2.415381e-07</td>\n",
       "      <td>0.203165</td>\n",
       "      <td>[0.041168, 0.041091, 0.042052, 0.041386, 0.041...</td>\n",
       "      <td>0.217466</td>\n",
       "      <td>3.889589e-05</td>\n",
       "      <td>0.466291</td>\n",
       "      <td>[0.221278, 0.223577, 0.216556, 0.216925, 0.204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>7</td>\n",
       "      <td>0.041613</td>\n",
       "      <td>3.650087e-07</td>\n",
       "      <td>0.203991</td>\n",
       "      <td>[0.042035, 0.040742, 0.041891, 0.042107, 0.042...</td>\n",
       "      <td>0.214141</td>\n",
       "      <td>1.486265e-05</td>\n",
       "      <td>0.462737</td>\n",
       "      <td>[0.215517, 0.215086, 0.219397, 0.206034, 0.213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>8</td>\n",
       "      <td>0.041932</td>\n",
       "      <td>5.857675e-07</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>[0.042655, 0.040895, 0.041599, 0.042866, 0.041...</td>\n",
       "      <td>0.209952</td>\n",
       "      <td>3.653254e-05</td>\n",
       "      <td>0.458166</td>\n",
       "      <td>[0.20197, 0.205911, 0.223645, 0.210345, 0.2108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>2.555202e-06</td>\n",
       "      <td>0.195716</td>\n",
       "      <td>[0.036709, 0.039906]</td>\n",
       "      <td>0.328631</td>\n",
       "      <td>4.900700e-05</td>\n",
       "      <td>0.573221</td>\n",
       "      <td>[0.335632, 0.321631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042126</td>\n",
       "      <td>2.673913e-06</td>\n",
       "      <td>0.205240</td>\n",
       "      <td>[0.039819, 0.043418, 0.043141]</td>\n",
       "      <td>0.300979</td>\n",
       "      <td>1.103747e-04</td>\n",
       "      <td>0.548515</td>\n",
       "      <td>[0.312581, 0.303215, 0.28714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042803</td>\n",
       "      <td>7.391922e-07</td>\n",
       "      <td>0.206888</td>\n",
       "      <td>[0.042539, 0.04426, 0.042371, 0.042043]</td>\n",
       "      <td>0.281949</td>\n",
       "      <td>5.407866e-05</td>\n",
       "      <td>0.530937</td>\n",
       "      <td>[0.288424, 0.287017, 0.269771, 0.282582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.043481</td>\n",
       "      <td>4.119596e-06</td>\n",
       "      <td>0.208511</td>\n",
       "      <td>[0.041266, 0.043036, 0.043726, 0.04719, 0.042186]</td>\n",
       "      <td>0.277514</td>\n",
       "      <td>1.009960e-04</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>[0.283251, 0.28202, 0.28611, 0.258084, 0.278103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045587</td>\n",
       "      <td>7.213748e-06</td>\n",
       "      <td>0.213495</td>\n",
       "      <td>[0.041907, 0.045747, 0.049664, 0.045895, 0.047...</td>\n",
       "      <td>0.273818</td>\n",
       "      <td>1.527947e-04</td>\n",
       "      <td>0.523130</td>\n",
       "      <td>[0.288511, 0.275684, 0.280488, 0.274205, 0.248...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>1.761827e-06</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>[0.045125, 0.042753, 0.042682, 0.044622, 0.043...</td>\n",
       "      <td>0.268213</td>\n",
       "      <td>1.138341e-04</td>\n",
       "      <td>0.517783</td>\n",
       "      <td>[0.284052, 0.26681, 0.273707, 0.274138, 0.2492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>0.044827</td>\n",
       "      <td>3.551248e-07</td>\n",
       "      <td>0.211723</td>\n",
       "      <td>[0.044415, 0.044133, 0.044837, 0.045611, 0.044...</td>\n",
       "      <td>0.264887</td>\n",
       "      <td>1.051895e-04</td>\n",
       "      <td>0.514570</td>\n",
       "      <td>[0.271429, 0.259606, 0.279803, 0.271429, 0.264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.116031</td>\n",
       "      <td>3.064730e-05</td>\n",
       "      <td>0.340588</td>\n",
       "      <td>[0.110495, 0.121567]</td>\n",
       "      <td>0.423478</td>\n",
       "      <td>8.176740e-06</td>\n",
       "      <td>0.650745</td>\n",
       "      <td>[0.420618, 0.426337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>3.290688e-05</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>[0.121951, 0.13358, 0.134596]</td>\n",
       "      <td>0.399951</td>\n",
       "      <td>7.916911e-06</td>\n",
       "      <td>0.632410</td>\n",
       "      <td>[0.401995, 0.401885, 0.395972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>8.033729e-05</td>\n",
       "      <td>0.365212</td>\n",
       "      <td>[0.138129, 0.12268, 0.14559, 0.127443]</td>\n",
       "      <td>0.388557</td>\n",
       "      <td>2.038614e-05</td>\n",
       "      <td>0.623327</td>\n",
       "      <td>[0.388916, 0.395664, 0.386056, 0.383592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.139866</td>\n",
       "      <td>1.663415e-05</td>\n",
       "      <td>0.373964</td>\n",
       "      <td>[0.135037, 0.142351, 0.136798, 0.14642, 0.138722]</td>\n",
       "      <td>0.383569</td>\n",
       "      <td>6.208729e-06</td>\n",
       "      <td>0.619324</td>\n",
       "      <td>[0.385468, 0.379926, 0.384971, 0.381275, 0.386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>3.419620e-06</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>[0.137694, 0.138645, 0.136354, 0.132732, 0.136...</td>\n",
       "      <td>0.379935</td>\n",
       "      <td>7.396558e-05</td>\n",
       "      <td>0.616328</td>\n",
       "      <td>[0.382342, 0.375092, 0.390244, 0.367332, 0.373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>0.134877</td>\n",
       "      <td>2.577954e-05</td>\n",
       "      <td>0.367221</td>\n",
       "      <td>[0.141194, 0.135158, 0.130991, 0.140404, 0.133...</td>\n",
       "      <td>0.373160</td>\n",
       "      <td>1.561960e-04</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>[0.392241, 0.360776, 0.362931, 0.381466, 0.365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137886</td>\n",
       "      <td>5.105215e-05</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>[0.137679, 0.146477, 0.135004, 0.127402, 0.135...</td>\n",
       "      <td>0.375871</td>\n",
       "      <td>7.146300e-05</td>\n",
       "      <td>0.613025</td>\n",
       "      <td>[0.367488, 0.368966, 0.372906, 0.388177, 0.368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.116031</td>\n",
       "      <td>3.064730e-05</td>\n",
       "      <td>0.340588</td>\n",
       "      <td>[0.110495, 0.121567]</td>\n",
       "      <td>0.423478</td>\n",
       "      <td>8.176740e-06</td>\n",
       "      <td>0.650745</td>\n",
       "      <td>[0.420618, 0.426337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>3.290688e-05</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>[0.121951, 0.13358, 0.134596]</td>\n",
       "      <td>0.399951</td>\n",
       "      <td>7.916911e-06</td>\n",
       "      <td>0.632410</td>\n",
       "      <td>[0.401995, 0.401885, 0.395972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.133584</td>\n",
       "      <td>7.772547e-05</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>[0.138129, 0.123173, 0.14559, 0.127443]</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>2.218359e-05</td>\n",
       "      <td>0.623424</td>\n",
       "      <td>[0.388916, 0.396157, 0.386056, 0.383592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.139866</td>\n",
       "      <td>1.663415e-05</td>\n",
       "      <td>0.373964</td>\n",
       "      <td>[0.135037, 0.142351, 0.136798, 0.14642, 0.138722]</td>\n",
       "      <td>0.383569</td>\n",
       "      <td>6.208729e-06</td>\n",
       "      <td>0.619324</td>\n",
       "      <td>[0.385468, 0.379926, 0.384971, 0.381275, 0.386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>3.419620e-06</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>[0.137694, 0.138645, 0.136354, 0.132732, 0.136...</td>\n",
       "      <td>0.379935</td>\n",
       "      <td>7.396558e-05</td>\n",
       "      <td>0.616328</td>\n",
       "      <td>[0.382342, 0.375092, 0.390244, 0.367332, 0.373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>0.134692</td>\n",
       "      <td>2.545879e-05</td>\n",
       "      <td>0.366970</td>\n",
       "      <td>[0.141194, 0.135158, 0.130991, 0.140404, 0.133...</td>\n",
       "      <td>0.372790</td>\n",
       "      <td>1.439031e-04</td>\n",
       "      <td>0.610448</td>\n",
       "      <td>[0.392241, 0.360776, 0.362931, 0.381466, 0.365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137939</td>\n",
       "      <td>4.996554e-05</td>\n",
       "      <td>0.371334</td>\n",
       "      <td>[0.137679, 0.146477, 0.135004, 0.127824, 0.135...</td>\n",
       "      <td>0.375255</td>\n",
       "      <td>5.896204e-05</td>\n",
       "      <td>0.612533</td>\n",
       "      <td>[0.367488, 0.368966, 0.372906, 0.383251, 0.368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.116031</td>\n",
       "      <td>3.064730e-05</td>\n",
       "      <td>0.340588</td>\n",
       "      <td>[0.110495, 0.121567]</td>\n",
       "      <td>0.423478</td>\n",
       "      <td>8.176740e-06</td>\n",
       "      <td>0.650745</td>\n",
       "      <td>[0.420618, 0.426337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>3.290688e-05</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>[0.121951, 0.13358, 0.134596]</td>\n",
       "      <td>0.399951</td>\n",
       "      <td>7.916911e-06</td>\n",
       "      <td>0.632410</td>\n",
       "      <td>[0.401995, 0.401885, 0.395972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>8.033729e-05</td>\n",
       "      <td>0.365212</td>\n",
       "      <td>[0.138129, 0.12268, 0.14559, 0.127443]</td>\n",
       "      <td>0.388557</td>\n",
       "      <td>2.038614e-05</td>\n",
       "      <td>0.623327</td>\n",
       "      <td>[0.388916, 0.395664, 0.386056, 0.383592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.139835</td>\n",
       "      <td>1.693538e-05</td>\n",
       "      <td>0.373922</td>\n",
       "      <td>[0.134883, 0.142351, 0.136798, 0.14642, 0.138722]</td>\n",
       "      <td>0.383876</td>\n",
       "      <td>7.756963e-06</td>\n",
       "      <td>0.619571</td>\n",
       "      <td>[0.387007, 0.379926, 0.384971, 0.381275, 0.386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>3.419620e-06</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>[0.137694, 0.138645, 0.136354, 0.132732, 0.136...</td>\n",
       "      <td>0.379935</td>\n",
       "      <td>7.396558e-05</td>\n",
       "      <td>0.616328</td>\n",
       "      <td>[0.382342, 0.375092, 0.390244, 0.367332, 0.373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>0.134764</td>\n",
       "      <td>2.631063e-05</td>\n",
       "      <td>0.367067</td>\n",
       "      <td>[0.141194, 0.135158, 0.130991, 0.140907, 0.133...</td>\n",
       "      <td>0.372790</td>\n",
       "      <td>1.439031e-04</td>\n",
       "      <td>0.610448</td>\n",
       "      <td>[0.392241, 0.360776, 0.362931, 0.381466, 0.365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137886</td>\n",
       "      <td>5.105215e-05</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>[0.137679, 0.146477, 0.135004, 0.127402, 0.135...</td>\n",
       "      <td>0.375994</td>\n",
       "      <td>6.950483e-05</td>\n",
       "      <td>0.613127</td>\n",
       "      <td>[0.368473, 0.368966, 0.372906, 0.388177, 0.368...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of cuts  Length of X  K fold  Train error  Train var. error  \\\n",
       "0                3          480       2     0.027468      7.404603e-07   \n",
       "1                3          480       3     0.028454      4.770576e-07   \n",
       "2                3          480       4     0.029562      1.845412e-07   \n",
       "3                3          480       5     0.029778      8.330122e-07   \n",
       "4                3          480       6     0.029759      5.156348e-07   \n",
       "5                3          480       7     0.030239      8.991320e-07   \n",
       "6                3          480       8     0.030292      4.266609e-07   \n",
       "7                4          240       2     0.034859      1.224342e-06   \n",
       "8                4          240       3     0.038800      6.881742e-07   \n",
       "9                4          240       4     0.039847      1.249681e-06   \n",
       "10               4          240       5     0.041094      6.294814e-07   \n",
       "11               4          240       6     0.041276      2.415381e-07   \n",
       "12               4          240       7     0.041613      3.650087e-07   \n",
       "13               4          240       8     0.041932      5.857675e-07   \n",
       "14               5          120       2     0.038307      2.555202e-06   \n",
       "15               5          120       3     0.042126      2.673913e-06   \n",
       "16               5          120       4     0.042803      7.391922e-07   \n",
       "17               5          120       5     0.043481      4.119596e-06   \n",
       "18               5          120       6     0.045587      7.213748e-06   \n",
       "19               5          120       7     0.044025      1.761827e-06   \n",
       "20               5          120       8     0.044827      3.551248e-07   \n",
       "21               6           60       2     0.116031      3.064730e-05   \n",
       "22               6           60       3     0.130042      3.290688e-05   \n",
       "23               6           60       4     0.133461      8.033729e-05   \n",
       "24               6           60       5     0.139866      1.663415e-05   \n",
       "25               6           60       6     0.136478      3.419620e-06   \n",
       "26               6           60       7     0.134877      2.577954e-05   \n",
       "27               6           60       8     0.137886      5.105215e-05   \n",
       "28               7           60       2     0.116031      3.064730e-05   \n",
       "29               7           60       3     0.130042      3.290688e-05   \n",
       "30               7           60       4     0.133584      7.772547e-05   \n",
       "31               7           60       5     0.139866      1.663415e-05   \n",
       "32               7           60       6     0.136478      3.419620e-06   \n",
       "33               7           60       7     0.134692      2.545879e-05   \n",
       "34               7           60       8     0.137939      4.996554e-05   \n",
       "35               8           60       2     0.116031      3.064730e-05   \n",
       "36               8           60       3     0.130042      3.290688e-05   \n",
       "37               8           60       4     0.133461      8.033729e-05   \n",
       "38               8           60       5     0.139835      1.693538e-05   \n",
       "39               8           60       6     0.136478      3.419620e-06   \n",
       "40               8           60       7     0.134764      2.631063e-05   \n",
       "41               8           60       8     0.137886      5.105215e-05   \n",
       "\n",
       "    Train bias error                                  Train list errors  \\\n",
       "0           0.165734                               [0.026608, 0.028329]   \n",
       "1           0.168681                     [0.028271, 0.029376, 0.027714]   \n",
       "2           0.171936            [0.028825, 0.02989, 0.029808, 0.029726]   \n",
       "3           0.172559  [0.02864, 0.031026, 0.028945, 0.030562, 0.029715]   \n",
       "4           0.172507  [0.028899, 0.029931, 0.030596, 0.030301, 0.028...   \n",
       "5           0.173892  [0.030754, 0.030466, 0.030969, 0.029173, 0.030...   \n",
       "6           0.174045  [0.031604, 0.029633, 0.030196, 0.030689, 0.030...   \n",
       "7           0.186701                               [0.033752, 0.035965]   \n",
       "8           0.196976                     [0.038803, 0.039815, 0.037783]   \n",
       "9           0.199615           [0.038269, 0.040729, 0.041058, 0.039333]   \n",
       "10          0.202716  [0.040727, 0.040111, 0.041493, 0.042417, 0.040...   \n",
       "11          0.203165  [0.041168, 0.041091, 0.042052, 0.041386, 0.041...   \n",
       "12          0.203991  [0.042035, 0.040742, 0.041891, 0.042107, 0.042...   \n",
       "13          0.204773  [0.042655, 0.040895, 0.041599, 0.042866, 0.041...   \n",
       "14          0.195716                               [0.036709, 0.039906]   \n",
       "15          0.205240                     [0.039819, 0.043418, 0.043141]   \n",
       "16          0.206888            [0.042539, 0.04426, 0.042371, 0.042043]   \n",
       "17          0.208511  [0.041266, 0.043036, 0.043726, 0.04719, 0.042186]   \n",
       "18          0.213495  [0.041907, 0.045747, 0.049664, 0.045895, 0.047...   \n",
       "19          0.209817  [0.045125, 0.042753, 0.042682, 0.044622, 0.043...   \n",
       "20          0.211723  [0.044415, 0.044133, 0.044837, 0.045611, 0.044...   \n",
       "21          0.340588                               [0.110495, 0.121567]   \n",
       "22          0.360568                      [0.121951, 0.13358, 0.134596]   \n",
       "23          0.365212             [0.138129, 0.12268, 0.14559, 0.127443]   \n",
       "24          0.373964  [0.135037, 0.142351, 0.136798, 0.14642, 0.138722]   \n",
       "25          0.369425  [0.137694, 0.138645, 0.136354, 0.132732, 0.136...   \n",
       "26          0.367221  [0.141194, 0.135158, 0.130991, 0.140404, 0.133...   \n",
       "27          0.371262  [0.137679, 0.146477, 0.135004, 0.127402, 0.135...   \n",
       "28          0.340588                               [0.110495, 0.121567]   \n",
       "29          0.360568                      [0.121951, 0.13358, 0.134596]   \n",
       "30          0.365385            [0.138129, 0.123173, 0.14559, 0.127443]   \n",
       "31          0.373964  [0.135037, 0.142351, 0.136798, 0.14642, 0.138722]   \n",
       "32          0.369425  [0.137694, 0.138645, 0.136354, 0.132732, 0.136...   \n",
       "33          0.366970  [0.141194, 0.135158, 0.130991, 0.140404, 0.133...   \n",
       "34          0.371334  [0.137679, 0.146477, 0.135004, 0.127824, 0.135...   \n",
       "35          0.340588                               [0.110495, 0.121567]   \n",
       "36          0.360568                      [0.121951, 0.13358, 0.134596]   \n",
       "37          0.365212             [0.138129, 0.12268, 0.14559, 0.127443]   \n",
       "38          0.373922  [0.134883, 0.142351, 0.136798, 0.14642, 0.138722]   \n",
       "39          0.369425  [0.137694, 0.138645, 0.136354, 0.132732, 0.136...   \n",
       "40          0.367067  [0.141194, 0.135158, 0.130991, 0.140907, 0.133...   \n",
       "41          0.371262  [0.137679, 0.146477, 0.135004, 0.127402, 0.135...   \n",
       "\n",
       "    Test error  Test var. error  Test bias error  \\\n",
       "0     0.212108     2.414740e-05         0.460526   \n",
       "1     0.176756     5.066776e-05         0.420364   \n",
       "2     0.169243     2.616685e-05         0.411359   \n",
       "3     0.161606     2.625967e-05         0.401969   \n",
       "4     0.158342     6.389788e-05         0.397841   \n",
       "5     0.157171     8.939856e-06         0.396437   \n",
       "6     0.152614     3.001696e-05         0.390620   \n",
       "7     0.274189     9.379922e-07         0.523629   \n",
       "8     0.239699     7.302089e-06         0.489583   \n",
       "9     0.228983     9.266302e-07         0.478521   \n",
       "10    0.220606     4.904469e-05         0.469635   \n",
       "11    0.217466     3.889589e-05         0.466291   \n",
       "12    0.214141     1.486265e-05         0.462737   \n",
       "13    0.209952     3.653254e-05         0.458166   \n",
       "14    0.328631     4.900700e-05         0.573221   \n",
       "15    0.300979     1.103747e-04         0.548515   \n",
       "16    0.281949     5.407866e-05         0.530937   \n",
       "17    0.277514     1.009960e-04         0.526700   \n",
       "18    0.273818     1.527947e-04         0.523130   \n",
       "19    0.268213     1.138341e-04         0.517783   \n",
       "20    0.264887     1.051895e-04         0.514570   \n",
       "21    0.423478     8.176740e-06         0.650745   \n",
       "22    0.399951     7.916911e-06         0.632410   \n",
       "23    0.388557     2.038614e-05         0.623327   \n",
       "24    0.383569     6.208729e-06         0.619324   \n",
       "25    0.379935     7.396558e-05         0.616328   \n",
       "26    0.373160     1.561960e-04         0.610740   \n",
       "27    0.375871     7.146300e-05         0.613025   \n",
       "28    0.423478     8.176740e-06         0.650745   \n",
       "29    0.399951     7.916911e-06         0.632410   \n",
       "30    0.388680     2.218359e-05         0.623424   \n",
       "31    0.383569     6.208729e-06         0.619324   \n",
       "32    0.379935     7.396558e-05         0.616328   \n",
       "33    0.372790     1.439031e-04         0.610448   \n",
       "34    0.375255     5.896204e-05         0.612533   \n",
       "35    0.423478     8.176740e-06         0.650745   \n",
       "36    0.399951     7.916911e-06         0.632410   \n",
       "37    0.388557     2.038614e-05         0.623327   \n",
       "38    0.383876     7.756963e-06         0.619571   \n",
       "39    0.379935     7.396558e-05         0.616328   \n",
       "40    0.372790     1.439031e-04         0.610448   \n",
       "41    0.375994     6.950483e-05         0.613127   \n",
       "\n",
       "                                     Test list errors  \n",
       "0                                [0.217022, 0.207194]  \n",
       "1                      [0.183263, 0.180155, 0.166851]  \n",
       "2            [0.175862, 0.171717, 0.167283, 0.162109]  \n",
       "3   [0.170567, 0.164101, 0.157376, 0.157376, 0.158...  \n",
       "4   [0.165127, 0.153363, 0.17221, 0.150776, 0.1504...  \n",
       "5   [0.159483, 0.159052, 0.160345, 0.159483, 0.152...  \n",
       "6   [0.149261, 0.159606, 0.157635, 0.156158, 0.150...  \n",
       "7                                 [0.275157, 0.27322]  \n",
       "8                      [0.243118, 0.239468, 0.236511]  \n",
       "9            [0.227833, 0.228381, 0.230352, 0.229367]  \n",
       "10  [0.220135, 0.231527, 0.220511, 0.209424, 0.221...  \n",
       "11  [0.221278, 0.223577, 0.216556, 0.216925, 0.204...  \n",
       "12  [0.215517, 0.215086, 0.219397, 0.206034, 0.213...  \n",
       "13  [0.20197, 0.205911, 0.223645, 0.210345, 0.2108...  \n",
       "14                               [0.335632, 0.321631]  \n",
       "15                      [0.312581, 0.303215, 0.28714]  \n",
       "16           [0.288424, 0.287017, 0.269771, 0.282582]  \n",
       "17   [0.283251, 0.28202, 0.28611, 0.258084, 0.278103]  \n",
       "18  [0.288511, 0.275684, 0.280488, 0.274205, 0.248...  \n",
       "19  [0.284052, 0.26681, 0.273707, 0.274138, 0.2492...  \n",
       "20  [0.271429, 0.259606, 0.279803, 0.271429, 0.264...  \n",
       "21                               [0.420618, 0.426337]  \n",
       "22                     [0.401995, 0.401885, 0.395972]  \n",
       "23           [0.388916, 0.395664, 0.386056, 0.383592]  \n",
       "24  [0.385468, 0.379926, 0.384971, 0.381275, 0.386...  \n",
       "25  [0.382342, 0.375092, 0.390244, 0.367332, 0.373...  \n",
       "26  [0.392241, 0.360776, 0.362931, 0.381466, 0.365...  \n",
       "27  [0.367488, 0.368966, 0.372906, 0.388177, 0.368...  \n",
       "28                               [0.420618, 0.426337]  \n",
       "29                     [0.401995, 0.401885, 0.395972]  \n",
       "30           [0.388916, 0.396157, 0.386056, 0.383592]  \n",
       "31  [0.385468, 0.379926, 0.384971, 0.381275, 0.386...  \n",
       "32  [0.382342, 0.375092, 0.390244, 0.367332, 0.373...  \n",
       "33  [0.392241, 0.360776, 0.362931, 0.381466, 0.365...  \n",
       "34  [0.367488, 0.368966, 0.372906, 0.383251, 0.368...  \n",
       "35                               [0.420618, 0.426337]  \n",
       "36                     [0.401995, 0.401885, 0.395972]  \n",
       "37           [0.388916, 0.395664, 0.386056, 0.383592]  \n",
       "38  [0.387007, 0.379926, 0.384971, 0.381275, 0.386...  \n",
       "39  [0.382342, 0.375092, 0.390244, 0.367332, 0.373...  \n",
       "40  [0.392241, 0.360776, 0.362931, 0.381466, 0.365...  \n",
       "41  [0.368473, 0.368966, 0.372906, 0.388177, 0.368...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cuts = 3\n",
    "max_cuts =  8\n",
    "max_folds = 8\n",
    "\n",
    "resultados_test_stratified_k_fold = test_k_fold(min_cuts,max_cuts,max_folds,k_fold_func=utils.get_stratified_k_fold_cross_validation)\n",
    "resultados_test_stratified_k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of cuts</th>\n",
       "      <th>Length of X</th>\n",
       "      <th>K subsets</th>\n",
       "      <th>Train error</th>\n",
       "      <th>Train var. error</th>\n",
       "      <th>Train bias error</th>\n",
       "      <th>Train list errors</th>\n",
       "      <th>Test error</th>\n",
       "      <th>Test var. error</th>\n",
       "      <th>Test bias error</th>\n",
       "      <th>Test list errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.162742</td>\n",
       "      <td>[0.026485]</td>\n",
       "      <td>0.213153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461685</td>\n",
       "      <td>[0.213153]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>5.595040e-07</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>[0.026485, 0.027981]</td>\n",
       "      <td>0.215512</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.464226</td>\n",
       "      <td>[0.213153, 0.21787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>1.323364e-06</td>\n",
       "      <td>0.162918</td>\n",
       "      <td>[0.026485, 0.027981, 0.025165]</td>\n",
       "      <td>0.216171</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.464937</td>\n",
       "      <td>[0.213153, 0.21787, 0.217489]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>1.070608e-06</td>\n",
       "      <td>0.163413</td>\n",
       "      <td>[0.026485, 0.027981, 0.025165, 0.027189]</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.466617</td>\n",
       "      <td>[0.213153, 0.21787, 0.217489, 0.222457]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026503</td>\n",
       "      <td>1.020349e-06</td>\n",
       "      <td>0.162793</td>\n",
       "      <td>[0.026485, 0.027981, 0.025165, 0.027189, 0.025...</td>\n",
       "      <td>0.217293</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.466137</td>\n",
       "      <td>[0.213153, 0.21787, 0.217489, 0.222457, 0.215495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>6</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>9.535876e-07</td>\n",
       "      <td>0.163234</td>\n",
       "      <td>[0.026485, 0.027981, 0.025165, 0.027189, 0.025...</td>\n",
       "      <td>0.218679</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.467613</td>\n",
       "      <td>[0.213153, 0.21787, 0.217489, 0.222457, 0.2154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037308</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.193153</td>\n",
       "      <td>[0.037308]</td>\n",
       "      <td>0.270250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519856</td>\n",
       "      <td>[0.27025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>6.969600e-08</td>\n",
       "      <td>0.192468</td>\n",
       "      <td>[0.037308, 0.03678]</td>\n",
       "      <td>0.273657</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.523111</td>\n",
       "      <td>[0.27025, 0.277064]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036604</td>\n",
       "      <td>4.336640e-07</td>\n",
       "      <td>0.191321</td>\n",
       "      <td>[0.037308, 0.03678, 0.035724]</td>\n",
       "      <td>0.275463</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.524832</td>\n",
       "      <td>[0.27025, 0.277064, 0.279076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>3.615480e-07</td>\n",
       "      <td>0.191033</td>\n",
       "      <td>[0.037308, 0.03678, 0.035724, 0.036164]</td>\n",
       "      <td>0.276883</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.526181</td>\n",
       "      <td>[0.27025, 0.277064, 0.279076, 0.281141]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036428</td>\n",
       "      <td>3.066624e-07</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>[0.037308, 0.03678, 0.035724, 0.036164, 0.036164]</td>\n",
       "      <td>0.275973</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.525315</td>\n",
       "      <td>[0.27025, 0.277064, 0.279076, 0.281141, 0.272334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "      <td>6</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>8.750720e-07</td>\n",
       "      <td>0.189935</td>\n",
       "      <td>[0.037308, 0.03678, 0.035724, 0.036164, 0.0361...</td>\n",
       "      <td>0.277486</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.526745</td>\n",
       "      <td>[0.27025, 0.277064, 0.279076, 0.281141, 0.2723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.192697</td>\n",
       "      <td>[0.037132]</td>\n",
       "      <td>0.322021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567469</td>\n",
       "      <td>[0.322021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037704</td>\n",
       "      <td>3.266123e-07</td>\n",
       "      <td>0.194173</td>\n",
       "      <td>[0.037132, 0.038275]</td>\n",
       "      <td>0.323269</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.568567</td>\n",
       "      <td>[0.322021, 0.324518]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036897</td>\n",
       "      <td>1.518626e-06</td>\n",
       "      <td>0.192082</td>\n",
       "      <td>[0.037132, 0.038275, 0.035284]</td>\n",
       "      <td>0.324695</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.569815</td>\n",
       "      <td>[0.322021, 0.324518, 0.327545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036846</td>\n",
       "      <td>1.146849e-06</td>\n",
       "      <td>0.191949</td>\n",
       "      <td>[0.037132, 0.038275, 0.035284, 0.036692]</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.572532</td>\n",
       "      <td>[0.322021, 0.324518, 0.327545, 0.337221]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>1.012282e-06</td>\n",
       "      <td>0.191548</td>\n",
       "      <td>[0.037132, 0.038275, 0.035284, 0.036692, 0.036...</td>\n",
       "      <td>0.327725</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.572449</td>\n",
       "      <td>[0.322021, 0.324518, 0.327545, 0.337221, 0.32732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.036575</td>\n",
       "      <td>9.123646e-07</td>\n",
       "      <td>0.191242</td>\n",
       "      <td>[0.037132, 0.038275, 0.035284, 0.036692, 0.036...</td>\n",
       "      <td>0.327741</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.572467</td>\n",
       "      <td>[0.322021, 0.324518, 0.327545, 0.337221, 0.327...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093709</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>[0.093709]</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639602</td>\n",
       "      <td>[0.409091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090673</td>\n",
       "      <td>9.217296e-06</td>\n",
       "      <td>0.301104</td>\n",
       "      <td>[0.093709, 0.087637]</td>\n",
       "      <td>0.416854</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>[0.409091, 0.424617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>2.250025e-05</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252]</td>\n",
       "      <td>0.416150</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.645065</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092631</td>\n",
       "      <td>1.931555e-05</td>\n",
       "      <td>0.304321</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925]</td>\n",
       "      <td>0.415059</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.644224</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092389</td>\n",
       "      <td>1.568660e-05</td>\n",
       "      <td>0.303929</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925, 0.091...</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.644343</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.091920</td>\n",
       "      <td>1.417338e-05</td>\n",
       "      <td>0.303159</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925, 0.091...</td>\n",
       "      <td>0.415980</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.644945</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093709</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>[0.093709]</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639602</td>\n",
       "      <td>[0.409091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090673</td>\n",
       "      <td>9.217296e-06</td>\n",
       "      <td>0.301104</td>\n",
       "      <td>[0.093709, 0.087637]</td>\n",
       "      <td>0.416854</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>[0.409091, 0.424617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093591</td>\n",
       "      <td>2.317820e-05</td>\n",
       "      <td>0.305889</td>\n",
       "      <td>[0.093709, 0.087637, 0.099428]</td>\n",
       "      <td>0.416066</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>[0.409091, 0.424617, 0.414491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092675</td>\n",
       "      <td>1.990403e-05</td>\n",
       "      <td>0.304393</td>\n",
       "      <td>[0.093709, 0.087637, 0.099428, 0.089925]</td>\n",
       "      <td>0.414996</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.644175</td>\n",
       "      <td>[0.409091, 0.424617, 0.414491, 0.411787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092424</td>\n",
       "      <td>1.617472e-05</td>\n",
       "      <td>0.303987</td>\n",
       "      <td>[0.093709, 0.087637, 0.099428, 0.089925, 0.091...</td>\n",
       "      <td>0.415155</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.644304</td>\n",
       "      <td>[0.409091, 0.424617, 0.414491, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.091949</td>\n",
       "      <td>1.460785e-05</td>\n",
       "      <td>0.303207</td>\n",
       "      <td>[0.093709, 0.087637, 0.099428, 0.089925, 0.091...</td>\n",
       "      <td>0.415938</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.644913</td>\n",
       "      <td>[0.409091, 0.424617, 0.414491, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093709</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>[0.093709]</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639602</td>\n",
       "      <td>[0.409091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090673</td>\n",
       "      <td>9.217296e-06</td>\n",
       "      <td>0.301104</td>\n",
       "      <td>[0.093709, 0.087637]</td>\n",
       "      <td>0.416854</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>[0.409091, 0.424617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093533</td>\n",
       "      <td>2.250025e-05</td>\n",
       "      <td>0.305794</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252]</td>\n",
       "      <td>0.416150</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.645065</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092631</td>\n",
       "      <td>1.931555e-05</td>\n",
       "      <td>0.304321</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925]</td>\n",
       "      <td>0.415059</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.644224</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092389</td>\n",
       "      <td>1.568660e-05</td>\n",
       "      <td>0.303929</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925, 0.091...</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.644343</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0.091920</td>\n",
       "      <td>1.417338e-05</td>\n",
       "      <td>0.303159</td>\n",
       "      <td>[0.093709, 0.087637, 0.099252, 0.089925, 0.091...</td>\n",
       "      <td>0.415980</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.644945</td>\n",
       "      <td>[0.409091, 0.424617, 0.414741, 0.411787, 0.415...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of cuts  Length of X  K subsets  Train error  Train var. error  \\\n",
       "0                3          480          1     0.026485      0.000000e+00   \n",
       "1                3          480          2     0.027233      5.595040e-07   \n",
       "2                3          480          3     0.026544      1.323364e-06   \n",
       "3                3          480          4     0.026705      1.070608e-06   \n",
       "4                3          480          5     0.026503      1.020349e-06   \n",
       "5                3          480          6     0.026646      9.535876e-07   \n",
       "6                4          240          1     0.037308      0.000000e+00   \n",
       "7                4          240          2     0.037044      6.969600e-08   \n",
       "8                4          240          3     0.036604      4.336640e-07   \n",
       "9                4          240          4     0.036494      3.615480e-07   \n",
       "10               4          240          5     0.036428      3.066624e-07   \n",
       "11               4          240          6     0.036076      8.750720e-07   \n",
       "12               5          120          1     0.037132      0.000000e+00   \n",
       "13               5          120          2     0.037704      3.266123e-07   \n",
       "14               5          120          3     0.036897      1.518626e-06   \n",
       "15               5          120          4     0.036846      1.146849e-06   \n",
       "16               5          120          5     0.036692      1.012282e-06   \n",
       "17               5          120          6     0.036575      9.123646e-07   \n",
       "18               6           60          1     0.093709      0.000000e+00   \n",
       "19               6           60          2     0.090673      9.217296e-06   \n",
       "20               6           60          3     0.093533      2.250025e-05   \n",
       "21               6           60          4     0.092631      1.931555e-05   \n",
       "22               6           60          5     0.092389      1.568660e-05   \n",
       "23               6           60          6     0.091920      1.417338e-05   \n",
       "24               7           60          1     0.093709      0.000000e+00   \n",
       "25               7           60          2     0.090673      9.217296e-06   \n",
       "26               7           60          3     0.093591      2.317820e-05   \n",
       "27               7           60          4     0.092675      1.990403e-05   \n",
       "28               7           60          5     0.092424      1.617472e-05   \n",
       "29               7           60          6     0.091949      1.460785e-05   \n",
       "30               8           60          1     0.093709      0.000000e+00   \n",
       "31               8           60          2     0.090673      9.217296e-06   \n",
       "32               8           60          3     0.093533      2.250025e-05   \n",
       "33               8           60          4     0.092631      1.931555e-05   \n",
       "34               8           60          5     0.092389      1.568660e-05   \n",
       "35               8           60          6     0.091920      1.417338e-05   \n",
       "\n",
       "    Train bias error                                  Train list errors  \\\n",
       "0           0.162742                                         [0.026485]   \n",
       "1           0.165023                               [0.026485, 0.027981]   \n",
       "2           0.162918                     [0.026485, 0.027981, 0.025165]   \n",
       "3           0.163413           [0.026485, 0.027981, 0.025165, 0.027189]   \n",
       "4           0.162793  [0.026485, 0.027981, 0.025165, 0.027189, 0.025...   \n",
       "5           0.163234  [0.026485, 0.027981, 0.025165, 0.027189, 0.025...   \n",
       "6           0.193153                                         [0.037308]   \n",
       "7           0.192468                                [0.037308, 0.03678]   \n",
       "8           0.191321                      [0.037308, 0.03678, 0.035724]   \n",
       "9           0.191033            [0.037308, 0.03678, 0.035724, 0.036164]   \n",
       "10          0.190860  [0.037308, 0.03678, 0.035724, 0.036164, 0.036164]   \n",
       "11          0.189935  [0.037308, 0.03678, 0.035724, 0.036164, 0.0361...   \n",
       "12          0.192697                                         [0.037132]   \n",
       "13          0.194173                               [0.037132, 0.038275]   \n",
       "14          0.192082                     [0.037132, 0.038275, 0.035284]   \n",
       "15          0.191949           [0.037132, 0.038275, 0.035284, 0.036692]   \n",
       "16          0.191548  [0.037132, 0.038275, 0.035284, 0.036692, 0.036...   \n",
       "17          0.191242  [0.037132, 0.038275, 0.035284, 0.036692, 0.036...   \n",
       "18          0.306119                                         [0.093709]   \n",
       "19          0.301104                               [0.093709, 0.087637]   \n",
       "20          0.305794                     [0.093709, 0.087637, 0.099252]   \n",
       "21          0.304321           [0.093709, 0.087637, 0.099252, 0.089925]   \n",
       "22          0.303929  [0.093709, 0.087637, 0.099252, 0.089925, 0.091...   \n",
       "23          0.303159  [0.093709, 0.087637, 0.099252, 0.089925, 0.091...   \n",
       "24          0.306119                                         [0.093709]   \n",
       "25          0.301104                               [0.093709, 0.087637]   \n",
       "26          0.305889                     [0.093709, 0.087637, 0.099428]   \n",
       "27          0.304393           [0.093709, 0.087637, 0.099428, 0.089925]   \n",
       "28          0.303987  [0.093709, 0.087637, 0.099428, 0.089925, 0.091...   \n",
       "29          0.303207  [0.093709, 0.087637, 0.099428, 0.089925, 0.091...   \n",
       "30          0.306119                                         [0.093709]   \n",
       "31          0.301104                               [0.093709, 0.087637]   \n",
       "32          0.305794                     [0.093709, 0.087637, 0.099252]   \n",
       "33          0.304321           [0.093709, 0.087637, 0.099252, 0.089925]   \n",
       "34          0.303929  [0.093709, 0.087637, 0.099252, 0.089925, 0.091...   \n",
       "35          0.303159  [0.093709, 0.087637, 0.099252, 0.089925, 0.091...   \n",
       "\n",
       "    Test error  Test var. error  Test bias error  \\\n",
       "0     0.213153         0.000000         0.461685   \n",
       "1     0.215512         0.000006         0.464226   \n",
       "2     0.216171         0.000005         0.464937   \n",
       "3     0.217742         0.000011         0.466617   \n",
       "4     0.217293         0.000009         0.466137   \n",
       "5     0.218679         0.000018         0.467613   \n",
       "6     0.270250         0.000000         0.519856   \n",
       "7     0.273657         0.000012         0.523111   \n",
       "8     0.275463         0.000014         0.524832   \n",
       "9     0.276883         0.000017         0.526181   \n",
       "10    0.275973         0.000017         0.525315   \n",
       "11    0.277486         0.000025         0.526745   \n",
       "12    0.322021         0.000000         0.567469   \n",
       "13    0.323269         0.000002         0.568567   \n",
       "14    0.324695         0.000005         0.569815   \n",
       "15    0.327826         0.000033         0.572532   \n",
       "16    0.327725         0.000027         0.572449   \n",
       "17    0.327741         0.000022         0.572467   \n",
       "18    0.409091         0.000000         0.639602   \n",
       "19    0.416854         0.000060         0.645596   \n",
       "20    0.416150         0.000041         0.645065   \n",
       "21    0.415059         0.000034         0.644224   \n",
       "22    0.415205         0.000028         0.644343   \n",
       "23    0.415980         0.000026         0.644945   \n",
       "24    0.409091         0.000000         0.639602   \n",
       "25    0.416854         0.000060         0.645596   \n",
       "26    0.416066         0.000041         0.645000   \n",
       "27    0.414996         0.000034         0.644175   \n",
       "28    0.415155         0.000028         0.644304   \n",
       "29    0.415938         0.000026         0.644913   \n",
       "30    0.409091         0.000000         0.639602   \n",
       "31    0.416854         0.000060         0.645596   \n",
       "32    0.416150         0.000041         0.645065   \n",
       "33    0.415059         0.000034         0.644224   \n",
       "34    0.415205         0.000028         0.644343   \n",
       "35    0.415980         0.000026         0.644945   \n",
       "\n",
       "                                     Test list errors  \n",
       "0                                          [0.213153]  \n",
       "1                                 [0.213153, 0.21787]  \n",
       "2                       [0.213153, 0.21787, 0.217489]  \n",
       "3             [0.213153, 0.21787, 0.217489, 0.222457]  \n",
       "4   [0.213153, 0.21787, 0.217489, 0.222457, 0.215495]  \n",
       "5   [0.213153, 0.21787, 0.217489, 0.222457, 0.2154...  \n",
       "6                                           [0.27025]  \n",
       "7                                 [0.27025, 0.277064]  \n",
       "8                       [0.27025, 0.277064, 0.279076]  \n",
       "9             [0.27025, 0.277064, 0.279076, 0.281141]  \n",
       "10  [0.27025, 0.277064, 0.279076, 0.281141, 0.272334]  \n",
       "11  [0.27025, 0.277064, 0.279076, 0.281141, 0.2723...  \n",
       "12                                         [0.322021]  \n",
       "13                               [0.322021, 0.324518]  \n",
       "14                     [0.322021, 0.324518, 0.327545]  \n",
       "15           [0.322021, 0.324518, 0.327545, 0.337221]  \n",
       "16  [0.322021, 0.324518, 0.327545, 0.337221, 0.32732]  \n",
       "17  [0.322021, 0.324518, 0.327545, 0.337221, 0.327...  \n",
       "18                                         [0.409091]  \n",
       "19                               [0.409091, 0.424617]  \n",
       "20                     [0.409091, 0.424617, 0.414741]  \n",
       "21           [0.409091, 0.424617, 0.414741, 0.411787]  \n",
       "22  [0.409091, 0.424617, 0.414741, 0.411787, 0.415...  \n",
       "23  [0.409091, 0.424617, 0.414741, 0.411787, 0.415...  \n",
       "24                                         [0.409091]  \n",
       "25                               [0.409091, 0.424617]  \n",
       "26                     [0.409091, 0.424617, 0.414491]  \n",
       "27           [0.409091, 0.424617, 0.414491, 0.411787]  \n",
       "28  [0.409091, 0.424617, 0.414491, 0.411787, 0.415...  \n",
       "29  [0.409091, 0.424617, 0.414491, 0.411787, 0.415...  \n",
       "30                                         [0.409091]  \n",
       "31                               [0.409091, 0.424617]  \n",
       "32                     [0.409091, 0.424617, 0.414741]  \n",
       "33           [0.409091, 0.424617, 0.414741, 0.411787]  \n",
       "34  [0.409091, 0.424617, 0.414741, 0.411787, 0.415...  \n",
       "35  [0.409091, 0.424617, 0.414741, 0.411787, 0.415...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cuts = 3\n",
    "max_cuts =  8\n",
    "max_subsets = 6 \n",
    "training_sample = 0.70\n",
    "\n",
    "resultados_test_bootstrap = test_bootstrap(min_cuts, max_cuts, max_subsets, training_sample)\n",
    "resultados_test_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Resultados/radial_basis_kernel/'\n",
    "resultados_test_stratified_k_fold.to_csv(output_path + 'stratified_k_fold.csv', sep = \";\")\n",
    "resultados_test_non_stratified_k_fold.to_csv(output_path + 'non_stratified_k_fold.csv', sep = \";\")\n",
    "resultados_test_bootstrap.to_csv(output_path + 'bootstrap.csv', sep = \";\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60ba1e9c20a97bab95adc8fa7cd7536eabf7ae0f08621d987aa706dba1e5c7d3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
